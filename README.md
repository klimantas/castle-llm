# ğŸ° CASTLE LLM Blue Agent

A training-free Large Language Model (LLM) based cyber defense agent designed for the [CAGE Challenge](https://github.com/CAGE-Challenge). This agent simulates blue-team behavior in a dynamic network environment without any fine-tuning or training, relying solely on prompt engineering and LLM inference.

---

## ğŸš€ Overview

The CASTLE Blue Agent defends a simulated enterprise network against advanced Red Team attacks by:

- Monitoring and analyzing suspicious activity
- Deploying honeypots to delay and deceive attackers
- Removing Red agent presence from compromised hosts
- Restoring critically compromised systems (with penalty)

The agent operates in a step-by-step simulation loop, observing network states and responding with defensive actions generated by an LLM.

---

## ğŸ§  Key Features

- **Training-free**: No fine-tuning or RL training required
- **Multi-LLM support**: Compatible with OpenAI and Dartmouth Chat models
- **Modular architecture**: Clean separation of concerns across components
- **Structured outputs**: Uses Pydantic models for reliable LLM response parsing
- **Reward-aware**: Aligns decisions with the CAGE Challenge reward function
- **Comprehensive evaluation**: Tracks metrics across episodes with detailed logging

---

## ğŸ•¸ï¸ Simulation Environment

The agent runs inside the [CybORG](https://github.com/cage-challenge/CybORG) simulation environment from the CAGE Challenge.

### Network Topology

- **Subnet 1** - User zone (entry point)
- **Subnet 2** - Enterprise server zone
- **Subnet 3** - Operational zone (critical infrastructure)

Red agents attempt to compromise Subnet 3 through reconnaissance, exploitation, privilege escalation, and impact attacks. Blue must detect and prevent them.

---

## ğŸ“¦ Installation

### Requirements

```bash
pip install -r requirements.txt
```

### API Key Setup

Create environment files for your API keys:

**For OpenAI:**
```bash
# openai_key.env
OPENAI_API_KEY=your_openai_api_key_here
```

**For Dartmouth Chat:**
```bash
# dartmouth_key.env
DARTMOUTH_CHAT_API_KEY=your_dartmouth_api_key_here
```

---

## âš™ï¸ Usage

### Running Evaluations

**With OpenAI models:**
```bash
python scripts/run_openai.py
```

**With Dartmouth Chat models:**
```bash
python scripts/run_dartmouth.py
```

### Configuration

Edit the respective script files to configure:
- Model selection (e.g., `gpt-4o-mini`, `gpt-4.1`)
- Temperature settings
- Number of episodes and steps
- Red agent type (`B_lineAgent` or `RedMeanderAgent`)

### Results

Evaluation results are automatically saved to `results/results_v{version}_{YYYYMM}/` with detailed JSON logs including:
- Episode rewards and step-by-step performance
- Action histories for both Blue and Red agents
- API and parsing failure statistics
- Red agent impact counts

---

## ğŸ“ Project Structure

```
castle-llm/
â”œâ”€â”€ src/                      # Core source code
â”‚   â”œâ”€â”€ agent.py             # Main agent logic and episode runner
â”‚   â”œâ”€â”€ actions.py           # Action conversion to CybORG format
â”‚   â”œâ”€â”€ environment.py       # Environment initialization and step execution
â”‚   â”œâ”€â”€ evaluation.py        # Evaluation runner and metrics
â”‚   â”œâ”€â”€ models.py            # Pydantic models for structured outputs
â”‚   â”œâ”€â”€ prompts.py           # Prompt loading and templates
â”‚   â”œâ”€â”€ config.py            # Configuration constants
â”‚   â””â”€â”€ llm/                 # LLM client implementations
â”‚       â”œâ”€â”€ base.py          # Base LLM client interface
â”‚       â”œâ”€â”€ openai_client.py # OpenAI implementation
â”‚       â””â”€â”€ dartmouth_client.py # Dartmouth Chat implementation
â”œâ”€â”€ scripts/                  # Evaluation scripts
â”‚   â”œâ”€â”€ run_openai.py        # Run with OpenAI models
â”‚   â””â”€â”€ run_dartmouth.py     # Run with Dartmouth models
â”œâ”€â”€ prompts/                  # Prompt templates
â”‚   â””â”€â”€ system_prompt.txt    # Main system prompt for the agent
â”œâ”€â”€ results/                  # Evaluation results (auto-generated)
â”œâ”€â”€ legacy_src/              # Archived legacy code
â””â”€â”€ CybORG/                  # CAGE Challenge simulation environment
```

---

## ğŸ“ Agent Architecture

### Decision Flow

1. **Observation**: Receive network state from CybORG environment
2. **LLM Query**: Send system prompt + history to LLM
3. **Parsing**: Parse structured JSON response into Action model
4. **Execution**: Convert to CybORG action and execute
5. **Update**: Record results and update history

### Action Space

**Reconnaissance:**
- `MONITOR` - Broad network scan
- `ANALYSE(host)` - Deep scan of specific host

**Deception:**
- `DECOY_APACHE(host)` - Deploy Apache honeypot
- `DECOY_FEMITTER(host)` - Deploy Femitter decoy
- `DECOY_HARAKASMPT(host)` - Deploy Haraka SMTP decoy
- `DECOY_SMSS(host)` - Deploy SMSS decoy
- `DECOY_SSHD(host)` - Deploy SSHD honeypot
- `DECOY_SVCHOST(host)` - Deploy Svchost decoy
- `DECOY_TOMCAT(host)` - Deploy Tomcat honeypot
- `DECOY_VSFTPD(host)` - Deploy VSFTPD honeypot

**Restorative:**
- `REMOVE(host)` - Remove Red presence (fails if Red has root)
- `RESTORE(host)` - Full system restore (works even with root access, -1 penalty)

**Other:**
- `SLEEP` - No operation

---

## ğŸ¯ Reward Structure

The agent optimizes for accumulated rewards based on:

| Event | Reward | Notes |
|-------|--------|-------|
| Red gains access to User hosts (Subnet 1) | -0.1/turn | Per compromised host |
| Red gains access to Enterprise servers (Subnet 2) | -1.0/turn | Per compromised server |
| Red gains access to Operational hosts (Subnet 3) | -0.1/turn | Per compromised host |
| Red gains access to Operational server (Subnet 3) | -1.0/turn | Critical target |
| Red performs Impact action | -10.0 | Severe penalty |
| Blue performs Restore | -1.0 | Cost of restoration |

---

## ğŸ”¬ Evaluation

The evaluation framework runs multiple episodes and tracks:

- **Total reward** per episode
- **Step-by-step rewards** throughout each episode
- **Action counts** for both Blue and Red agents
- **Impact events** (critical Red agent attacks)
- **API failures** (when LLM calls fail)
- **Parsing failures** (when LLM output is invalid)
- **Failure rates** for reliability analysis

Results are saved as timestamped JSON files for analysis and comparison across different models and configurations.

---

## ğŸ› ï¸ Development

### Adding New LLM Providers

1. Create a new client in `src/llm/` inheriting from `BaseLLMClient`
2. Implement the `get_action()` method
3. Add a corresponding run script in `scripts/`

### Modifying the Prompt

Edit `prompts/system_prompt.txt` to adjust the agent's behavior. The prompt includes:
- Network topology description
- Available actions and their effects
- Reward structure
- Strategic guidance

### Testing

Run evaluations with different configurations:
- Multiple models
- Different temperatures
- Various Red agent types
- Different episode lengths

---

## ğŸ“Š Example Results

Typical performance metrics (30 steps per episode):

- **Average reward**: -5 to -15 (depending on Red agent)
- **API failure rate**: < 5%
- **Parsing failure rate**: < 2%
- **Impact events prevented**: 80-95%

Results vary based on model selection, temperature, and Red agent strategy.

---

## ğŸ“„ License

See [LICENSE.txt](LICENSE.txt) for details.

---

## ğŸ™ Acknowledgments

Built on top of:
- [CAGE Challenge](https://github.com/cage-challenge/cage-challenge-4) - Cyber defense simulation
- [CybORG](https://github.com/cage-challenge/CybORG) - Network simulation environment

---

## ğŸ“¬ Contact

For questions or contributions, please open an issue on the repository.
